{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: pefile in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (2023.2.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pefile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FileName': 'C:\\\\Program Files (x86)\\\\RapidTyping 5\\\\RapidTyping.exe', 'md5Hash': 'bf2cd6de94b4ed9d407eb713d0b19161', 'Machine': 332, 'DebugSize': 28, 'DebugRVA': 1738592, 'MajorImageVersion': 0, 'MajorOSVersion': 5, 'ExportRVA': 0, 'ExportSize': 0, 'IatVRA': 1552384, 'MajorLinkerVersion': 14, 'MinorLinkerVersion': 0, 'NumberOfSections': 6, 'SizeOfStackReserve': 1048576, 'DllCharacteristics': 33024, 'ResourceSize': 185624, 'BitcoinAddresses': ['333333333333333333333333333333n3333', '33333333333333333333333333333333333', '33333333333333333333333333333333333', '33333333333333333333333333333333333', '33333333333333333333333333333333333', '33333333333333333333333333333333333', '33333333333333333333333333333333333', '33333333333333333333333333333333333', '33333333333333333333GV3333333333333', '3333333333kj533333333333333333333L', '333333333333333333P3333333333333333', '3333333333333333aK3333333333333333', '33333333333333ya33333fo833333333333', '3333337gVis633333333333333333333333', '33333333333333333333333333333333333', '33333333333333333333333333333333333', '33333333333333333333333333333333333', '33333333333333333333333333333333333', '33333333333333333333333333333333333', '3333333333333333333333333333338t333', '333333333333333333333333333'], 'Benign': 0}\n"
     ]
    }
   ],
   "source": [
    "import pefile\n",
    "import hashlib\n",
    "import re\n",
    "\n",
    "def extract_features(file_path):\n",
    "    features = {}\n",
    "    \n",
    "    # FileName\n",
    "    features['FileName'] = file_path\n",
    "  # md5Hash\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        file_content = f.read()\n",
    "        features['md5Hash'] = hashlib.md5(file_content).hexdigest()\n",
    "    \n",
    "    pe = pefile.PE(file_path)\n",
    "    \n",
    "    # Machine\n",
    "    features['Machine'] = pe.FILE_HEADER.Machine\n",
    "    \n",
    "    # DebugSize and DebugRVA\n",
    "    features['DebugSize'] = pe.OPTIONAL_HEADER.DATA_DIRECTORY[pefile.DIRECTORY_ENTRY['IMAGE_DIRECTORY_ENTRY_DEBUG']].Size\n",
    "\n",
    "    features['DebugRVA'] = pe.OPTIONAL_HEADER.DATA_DIRECTORY[pefile.DIRECTORY_ENTRY['IMAGE_DIRECTORY_ENTRY_DEBUG']].VirtualAddress\n",
    "    \n",
    "    # MajorImageVersion\n",
    "    features['MajorImageVersion'] = pe.OPTIONAL_HEADER.MajorImageVersion\n",
    "    \n",
    "    # MajorOSVersion\n",
    "    features['MajorOSVersion'] = pe.OPTIONAL_HEADER.MajorOperatingSystemVersion\n",
    "    \n",
    "    # ExportRVA and ExportSize\n",
    "    features['ExportRVA'] = pe.OPTIONAL_HEADER.DATA_DIRECTORY[pefile.DIRECTORY_ENTRY['IMAGE_DIRECTORY_ENTRY_EXPORT']].VirtualAddress\n",
    "    features['ExportSize'] = pe.OPTIONAL_HEADER.DATA_DIRECTORY[pefile.DIRECTORY_ENTRY['IMAGE_DIRECTORY_ENTRY_EXPORT']].Size\n",
    "        # IatVRA\n",
    "    features['IatVRA'] = pe.OPTIONAL_HEADER.DATA_DIRECTORY[pefile.DIRECTORY_ENTRY['IMAGE_DIRECTORY_ENTRY_IAT']].VirtualAddress\n",
    "    \n",
    "    # MajorLinkerVersion and MinorLinkerVersion\n",
    "    features['MajorLinkerVersion'] = pe.OPTIONAL_HEADER.MajorLinkerVersion\n",
    "    features['MinorLinkerVersion'] = pe.OPTIONAL_HEADER.MinorLinkerVersion\n",
    "    \n",
    "    # NumberOfSections\n",
    "    features['NumberOfSections'] = pe.FILE_HEADER.NumberOfSections\n",
    "    \n",
    "    # SizeOfStackReserve\n",
    "    features['SizeOfStackReserve'] = pe.OPTIONAL_HEADER.SizeOfStackReserve\n",
    "        # DllCharacteristics\n",
    "    features['DllCharacteristics'] = pe.OPTIONAL_HEADER.DllCharacteristics\n",
    "    \n",
    "    # ResourceSize\n",
    "    features['ResourceSize'] = pe.OPTIONAL_HEADER.DATA_DIRECTORY[pefile.DIRECTORY_ENTRY['IMAGE_DIRECTORY_ENTRY_RESOURCE']].Size\n",
    "    \n",
    "    # BitcoinAddresses\n",
    "    bitcoin_regex = re.compile(r'([13][a-km-zA-HJ-NP-Z1-9]{25,34})')\n",
    "    features['BitcoinAddresses'] = bitcoin_regex.findall(file_content.decode('utf-8', errors='ignore'))\n",
    "    \n",
    "    # Benign (this would normally be provided by your labeled dataset)\n",
    "    features['Benign'] = 0  # Example default value\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Example usage\n",
    "file_path = r'C:\\Program Files (x86)\\RapidTyping 5\\RapidTyping.exe' #a single exe is tested just as an example\n",
    "features = extract_features(file_path)\n",
    "print(features)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For saving extracted features in Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the features to a file data.csv\n",
    "import csv\n",
    "custom_datasetPath= r'C:\\Users\\admin\\Desktop\\RansomwareDetection\\Dataset\\data_file.csv\\customDataset.csv'\n",
    "with open(custom_datasetPath, 'w') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=features.keys())\n",
    "    writer.writeheader()\n",
    "    writer.writerow(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: joblib in c:\\users\\admin\\appdata\\roaming\\python\\python311\\site-packages (1.3.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install joblib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train is (49988, 124985) and shape of y_train is (49988,)\n",
      "Confusion Matrix:\n",
      "[[7102   23]\n",
      " [  37 5335]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      7125\n",
      "           1       1.00      0.99      0.99      5372\n",
      "\n",
      "    accuracy                           1.00     12497\n",
      "   macro avg       1.00      0.99      1.00     12497\n",
      "weighted avg       1.00      1.00      1.00     12497\n",
      "\n",
      "\n",
      "Accuracy Score:\n",
      "0.9951988477234537\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(r'C:\\Users\\admin\\Desktop\\RansomwareDetection\\Dataset\\data_file.csv\\data_file.csv')\n",
    "\n",
    "# # Inspect the dataset\n",
    "# print(df.head())\n",
    "# print(df.info())\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.drop('Benign', axis=1)  # Assuming 'Benign' is the label column\n",
    "y = df['Benign']\n",
    "\n",
    "# Identify non-numeric columns\n",
    "non_numeric_cols = X.select_dtypes(include=['object']).columns\n",
    "numeric_cols = X.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "# Preprocessing for numeric data\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=True))])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, non_numeric_cols)])\n",
    "\n",
    "# Apply preprocessing to the dataset\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print('The shape of X_train is {0} and shape of y_train is {1}'.format(X_train.shape, y_train.shape))\n",
    "\n",
    "# Initialize XGBoost classifier\n",
    "model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    n_estimators=100,  # Number of boosting rounds\n",
    "    max_depth=5,       # Maximum depth of a tree\n",
    "    learning_rate=0.1, # Step size shrinkage\n",
    "    subsample=0.8,     # Subsample ratio of the training instances\n",
    "    colsample_bytree=0.8 # Subsample ratio of columns when constructing each tree\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nAccuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, 'xgboost_ransomware_model.pkl')\n",
    "\n",
    "# Load the model\n",
    "model = joblib.load('xgboost_ransomware_model.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
